---

- name: Get Slurm hostnames
  vars:
    - index: "{{ unreachable_nodes | ansible.netcommon.ipsubnet(hostvars[inventory_hostname]['private_subnet']) }}"
    - keyword: "{% for partition in queues %}{% for instance in partition.instance_types %}{% if instance.name == instance_type %}{{instance.instance_keyword}}{% endif %}{% endfor %}{% endfor %}"
  set_fact:
    unreachable_slurm_nodes: "{{unreachable_slurm_nodes | default([]) + [queue+'-'+keyword+'-node-'+ item | ansible.netcommon.ipsubnet(hostvars[inventory_hostname]['private_subnet']) ] }}"
  with_items: "{{unreachable_nodes}}"
  when: item | ipaddr
  ignore_unreachable: yes
  delegate_to: 127.0.0.1
  run_once: true

- name: Get Slurm hostnames
  set_fact:
    unreachable_slurm_nodes: "{{unreachable_slurm_nodes | default([]) + [item] }}"
  with_items: "{{unreachable_nodes}}"
  when: not ( item | ipaddr ) and '-node-' in item
  ignore_unreachable: yes
  delegate_to: 127.0.0.1
  run_once: true

- name: Get non-Slurm hostnames
  set_fact:
    unreachable_oci_nodes: "{{unreachable_slurm_nodes | default([]) + [item] }}"
  with_items: "{{unreachable_nodes}}"
  when: not ( item | ipaddr ) and not ('-node-' in item )
  ignore_unreachable: yes
  delegate_to: 127.0.0.1
  run_once: true

- name: Get all hostnames
  set_fact: 
    all_unreachable_nodes: "{{ unreachable_slurm_nodes | default([]) + unreachable_oci_nodes | default([]) }}"
  delegate_to: 127.0.0.1
  run_once: true
  ignore_unreachable: yes

- name: remove from /etc/hosts
  become: true
  lineinfile:
    path: "/etc/hosts"
    regexp: "{{item}}\\s"
    state: absent
  with_items: "{{all_unreachable_nodes}}"
  ignore_unreachable: yes

- name: "remove from hostfile.rdma.{{ cluster_name }}"
  lineinfile:
    path: "/etc/opt/oci-hpc/hostfile.rdma.{{ cluster_name }}"
    regexp: "{{item}}\\s"
    state: absent
  with_items: "{{all_unreachable_nodes}}"
  delegate_to: 127.0.0.1
  run_once: true
  ignore_unreachable: yes
  when: cluster_network|bool

- name: "remove from hostfile.tcp.{{ cluster_name }}"
  lineinfile:
    path: "/etc/opt/oci-hpc/hostfile.tcp.{{ cluster_name }}"
    regexp: "{{item}}\\s"
    state: absent
  with_items: "{{all_unreachable_nodes}}"
  ignore_unreachable: yes
  delegate_to: 127.0.0.1
  run_once: true

- name: remove from hostfile.rdma
  lineinfile:
    path: "/etc/opt/oci-hpc/hostfile.rdma"
    regexp: "{{item}}\\s"
    state: absent
  with_items: "{{all_unreachable_nodes}}"
  ignore_unreachable: yes
  when: cluster_network|bool

- name: remove from hostfile.tcp
  lineinfile:
    path: "/etc/opt/oci-hpc/hostfile.tcp"
    regexp: "{{item}}\\s"
    state: absent
  with_items: "{{all_unreachable_nodes}}"
  ignore_unreachable: yes

- name: get SwitchLine
  shell: "scontrol show hostname `scontrol show topology {{item}} | grep -v inactive-  | rev | cut -d \"=\" -f 1 | rev`"
  register: current_switch
  run_once: true
  delegate_to: 127.0.0.1
  with_items: "{{unreachable_slurm_nodes}}"

- name: getNodes
  set_fact:
    nodes_on_switch: "{{nodes_on_switch | default({}) | combine({item.item : item.stdout_lines } ) }}"
  with_items: "{{current_switch.results}}"
  run_once: true
  delegate_to: 127.0.0.1
  when: ( item.stdout_lines | length ) > 0

- name: getNodes
  set_fact:
    nodes_on_switch: "{{nodes_on_switch | default({}) | combine({item.item : [] } ) }}"
  with_items: "{{current_switch.results}}"
  run_once: true
  delegate_to: 127.0.0.1
  when: ( item.stdout_lines | length ) == 0

- name: get SwitchNames
  shell: "scontrol show topology {{item}} | grep -v inactive | awk '{print $1}' | cut -d \"=\" -f 2"
  register: current_switchName
  run_once: true
  delegate_to: 127.0.0.1
  with_items: "{{unreachable_slurm_nodes}}"

- name: get Switchname
  set_fact:
    switchnames: "{{switchnames | default({}) | combine({item.item : item.stdout} ) }}"
  with_items: "{{current_switchName.results}}"
  run_once: true
  delegate_to: 127.0.0.1
  when: ( item.stdout_lines | length ) > 0

- name: get Switchname
  set_fact:
    switchnames: "{{switchnames | default({}) | combine({item.item : \"\" }) }}"
  with_items: "{{current_switchName.results}}"
  run_once: true
  delegate_to: 127.0.0.1
  when: ( item.stdout_lines | length ) == 0


- name: remove line from topology
  lineinfile:
    path: "{{ slurm_conf_path }}/topology.conf"
    regexp: "SwitchName={{switchnames[item]}}\\sNodes=.*"
    state: absent
  with_items: "{{unreachable_slurm_nodes}}"
  ignore_unreachable: yes
  when: ( not switchnames[item] is match("inactive-.*") ) and ( ( nodes_on_switch[item] | length ) < 2 ) and ( switchnames[item] | length ) > 1
  run_once: true
  delegate_to: 127.0.0.1

- name: generate nodes_on_switch_condensed
  shell: "scontrol show hostlistsorted {{nodes_on_switch[item] | difference([item]) | join(',')}}"
  register: switch_condensed
  with_items: "{{unreachable_slurm_nodes}}"
  ignore_unreachable: yes
  when: ( not switchnames[item] is match("inactive-.*") ) and ( ( nodes_on_switch[item] | length ) > 1 ) and ( switchnames[item] | length ) > 1
  run_once: true
  delegate_to: 127.0.0.1

- name: get condensed_Nodes
  set_fact:
    nodes_on_switch_condensed: "{{nodes_on_switch_condensed | default({}) | combine({item.item : item.stdout } ) }}"
  with_items: "{{switch_condensed.results}}"
  run_once: true
  delegate_to: 127.0.0.1
  ignore_errors: yes

- name: remove line from topology
  lineinfile:
    path: "{{ slurm_conf_path }}/topology.conf"
    regexp: "SwitchName={{switchnames[item]}}\\sNodes.*"
    line: "SwitchName={{switchnames[item]}} Nodes={{nodes_on_switch_condensed[item]}}"
    state: present
  with_items: "{{unreachable_slurm_nodes}}"
  ignore_errors: yes
  when: ( not switchnames[item] is match("inactive-.*") ) and ( ( nodes_on_switch_condensed[item] | length ) > 1 )
  run_once: true
  delegate_to: 127.0.0.1

- name: get inactiveLine
  shell: "scontrol show hostname `scontrol show topology inactive-{{item.split('-node-')[0]}} | rev | cut -d \"=\" -f 1 | rev`"
  register: inactive_switch
  run_once: true
  delegate_to: 127.0.0.1
  with_items: "{{unreachable_slurm_nodes}}"

- name: get Inactive Nodes
  set_fact:
    nodes_on_inactive_switch: "{{nodes_on_inactive_switch | default({}) | combine({item.item : item.stdout_lines } ) }}"
  with_items: "{{inactive_switch.results}}"
  run_once: true
  delegate_to: 127.0.0.1
  when: ( item.stdout_lines | length ) > 0

- name: get Inactive Nodes
  set_fact:
    nodes_on_inactive_switch: "{{nodes_on_inactive_switch | default({}) | combine({item.item : [] } ) }}"
  with_items: "{{inactive_switch.results}}"
  run_once: true
  delegate_to: 127.0.0.1
  when: ( item.stdout_lines | length ) == 0

- name: generate nodes_on_inactive_switch_condensed
  shell: "scontrol show hostlistsorted {{nodes_on_inactive_switch[item] | union([item]) | join(',')}}"
  register: inactive_switch_condensed
  with_items: "{{unreachable_slurm_nodes}}"
  run_once: true
  delegate_to: 127.0.0.1

- name: get condensed_Nodes
  set_fact:
    nodes_on_switch_condensed: "{{nodes_on_inactive_switch_condensed | default({}) | combine({item.item : item.stdout } ) }}"
  with_items: "{{inactive_switch_condensed.results}}"
  run_once: true
  delegate_to: 127.0.0.1


- name: add node to inactive line
  lineinfile:
    path: "{{ slurm_conf_path }}/topology.conf"
    regexp: "SwitchName=inactive-{{item.split('-node-')[0]}}\\sNodes.*"
    line: "SwitchName=inactive-{{item.split('-node-')[0]}} Nodes={{nodes_on_switch_condensed[item]}}"
    state: present
  with_items: "{{unreachable_slurm_nodes}}"
  ignore_unreachable: yes
  delegate_to: 127.0.0.1
  run_once: true

- name: change Node Status
  become: true
  command: "scontrol update nodename={{ item }} state=future reason=terminating"
  ignore_errors: force
  ignore_unreachable: True
  with_items: "{{unreachable_slurm_nodes}}"
  delegate_to: 127.0.0.1
  when: ('bastion' in group_names)

- name: Reconfigure Slurm for topology
  become: true
  command: "scontrol reconfigure"
  delegate_to: 127.0.0.1
  run_once: true